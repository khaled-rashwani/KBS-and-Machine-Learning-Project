{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b91040c-cd6a-4c0a-b471-00597d5c744a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import scipy.special\n",
    "import torch\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import re\n",
    "import PyPDF2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from experta import *\n",
    "\n",
    "# Load the stopwords\n",
    "with open(\"stopwords.txt\", \"r\") as f:\n",
    "    stopwords = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "# Load the Loughran-McDonald dictionary\n",
    "lm_dict = pd.read_csv(\"Loughran-McDonald_MasterDictionary_1993-2023.csv\")\n",
    "pos_words = lm_dict[lm_dict[\"Positive\"] != 0][\"Word\"].str.lower().to_list()\n",
    "neg_words = lm_dict[lm_dict[\"Negative\"] != 0][\"Word\"].str.lower().to_list()\n",
    "\n",
    "# Load FinBert model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    words = text.split()\n",
    "    words = [w.lower() for w in words]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    words = [w for w in words if w not in stopwords]\n",
    "    \n",
    "    # Remove punctuation and numbers\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    \n",
    "    return \" \".join(words)\n",
    "\n",
    "def calculate_sentiment(text):\n",
    "    words = text.split()\n",
    "    n_pos = len([w for w in words if w in pos_words])\n",
    "    n_neg = len([w for w in words if w in neg_words])\n",
    "    n_total = len(words)\n",
    "    \n",
    "    # Print the number of positive and negative words\n",
    "    print(f\"Positive words count: {n_pos}\")\n",
    "    print(f\"Negative words count: {n_neg}\")\n",
    "    print(f\"Total words count: {n_total}\")\n",
    "    if n_total == 0:\n",
    "        print(\"No words to analyze. Sentiment is neutral by default.\")\n",
    "        return 0, 0, \"neutral\"\n",
    "\n",
    "    # Calculate Loughran-McDonald Scores\n",
    "    lm_score1 = (n_pos - n_neg) / n_total\n",
    "    lm_score2 = (n_pos - n_neg) / (n_pos + n_neg) if (n_pos + n_neg) != 0 else 0\n",
    "\n",
    "    print(f\"Loughran-McDonald Score 1: {lm_score1:.4f}\")\n",
    "    print(f\"Loughran-McDonald Score 2: {lm_score2:.4f}\")\n",
    "    cutoff=-0.4\n",
    "    # Determine sentiment based on lm_score2 and a customizable cutoff\n",
    "    if lm_score2 > cutoff:\n",
    "        sentiment = \"positive\"\n",
    "    elif lm_score2 < -cutoff:\n",
    "        sentiment = \"negative\"\n",
    "    else:\n",
    "        sentiment = \"neutral\"\n",
    "\n",
    "    print(f\"Final Sentiment: {sentiment.capitalize()}\")\n",
    "\n",
    "    return lm_score1, lm_score2, sentiment\n",
    "    \n",
    "#     return lm_score1, lm_score2, sentiment\n",
    "\n",
    "def get_finbert_sentiment(text: str) -> tuple[float, float, float, str]:\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(\n",
    "            text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512\n",
    "        )\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        scores = {\n",
    "            k: v\n",
    "            for k, v in zip(\n",
    "                model.config.id2label.values(),\n",
    "                scipy.special.softmax(logits.numpy().squeeze()),\n",
    "            )\n",
    "        }\n",
    "        return (\n",
    "            scores[\"positive\"],\n",
    "            scores[\"negative\"],\n",
    "            scores[\"neutral\"],\n",
    "            max(scores, key=scores.get),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "500b5ed7-8d6c-4c76-88e1-f8492d5bb6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example interpretation functions\n",
    "def interpret_beneish_score(results):\n",
    "    if results['M-Score'] < -1.78:\n",
    "        return \"Depends on Beneish M Score Indicator, this analysis indicates a low probability of earnings manipulation for the company.\"\n",
    "    elif -1.78 <= results['M-Score'] <= -1.22:\n",
    "        return \"Depends on Beneish M Score Indicator, this analysis indicates a moderate probability of earnings manipulation for the company.\"\n",
    "    else:\n",
    "        return \"Depends on Beneish M Score Indicator, this analysis suggests a high probability of earnings manipulation for the company.\"\n",
    "\n",
    "def interpret_piotroski_score(results):\n",
    "    score = results.get('PiotroskiFScore', 0)\n",
    "    common = (\"\\n\"\n",
    "        \"Net Income: Indicates if the company is profitable.\\n\"\n",
    "        \"Return on Assets (ROA): Reflects the efficiency of asset use.\\n\"\n",
    "        \"Cash Flow from Operations (CFO): Shows operational cash generation.\\n\"\n",
    "        \"Accrual Accounting: Compares CFO to Net Income.\\n\"\n",
    "        \"Leverage: Lower leverage is preferred compared to the previous year.\\n\"\n",
    "        \"Liquidity: Higher current ratio compared to the previous year is favorable.\\n\"\n",
    "        \"Dilution: No increase in shares outstanding indicates better equity health.\\n\"\n",
    "        \"Gross Margin: Indicates cost control relative to revenue.\\n\"\n",
    "        \"Asset Turnover: Higher turnover indicates better asset utilization.\\n\"\n",
    "    )\n",
    "    if score >= 8:\n",
    "        return \"Depends on Piotroski Indicator, The company shows a strong financial position.\\n\" + common\n",
    "    elif 5 <= score < 8:\n",
    "        return \"Depends on Piotroski Indicator, The company has a moderate financial position.\\n\" + common\n",
    "    else:\n",
    "        return \"Depends on Piotroski Indicator, The company is in a weak financial position.\\n\" + common\n",
    "\n",
    "def interpret_springate_score(results):\n",
    "    score = results.get('SpringateScore', 0)\n",
    "    if score > 0.862:\n",
    "        return \"Depends on Springate Indicator, The company is in a stable state.\"\n",
    "    else:\n",
    "        return \"Depends on Springate Indicator, The company might be under financial stress.\"\n",
    "\n",
    "def interpret_sentiment(lm_sentiment, finbert_sentiment):\n",
    "    sentiments = {\n",
    "        'positive': (\"The overall sentiment is positive, suggesting a favorable financial outlook.\", \"green\"),\n",
    "        'negative': (\"The overall sentiment is negative, indicating potential concerns.\", \"red\"),\n",
    "        'neutral': (\"The overall sentiment is neutral, implying a stable outlook.\", \"gray\")\n",
    "    }\n",
    "    \n",
    "    lm_interpretation, lm_color = sentiments.get(lm_sentiment.lower(), (\"Unclear\", \"black\"))\n",
    "    finbert_interpretation, finbert_color = sentiments.get(finbert_sentiment.lower(), (\"Unclear\", \"black\"))\n",
    "    \n",
    "    return f\"\"\"\n",
    "    <p style=\"color: {lm_color};\">Loughran-McDonald Sentiment: {lm_interpretation}</p>\n",
    "    <p style=\"color: {finbert_color};\">FinBERT Sentiment: {finbert_interpretation}</p>\n",
    "    \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594018c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
